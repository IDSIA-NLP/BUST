{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_file = \"../results/databricks-dolly_size-2000.csv\"\n",
    "replace1_data_file = \"../results/databricks-dolly_size-2000_repl1.csv\" \n",
    "replace2_data_file = \"../results/databricks-dolly_size-2000_repl2.csv\"\n",
    "# MIN TEMP\n",
    "ablation_min_temp_data_file = \"../results/databricks-dolly_size-2000_ABLATION-TEMPERATURE-MIN.csv\"\n",
    "ablation_min_temp_data_file_L2_70B = \"../results/databricks-dolly_size-2000_ABLATION_TEMPERATURE_MIN.csv\"\n",
    "# MAX TEMP\n",
    "ablation_max_temp_data_file = \"../results/databricks-dolly_size-2000_ABLATION-TEMPERATURE-MAX.ckpt.csv\"\n",
    "ablation_max_temp_data_file_GPT4 = \"../results/...\"\n",
    "\n",
    "# LENGTH\n",
    "ablation_length_data_file = \"../results/databricks-dolly_size-2000_ABLATION_LENGTH.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(main_data_file)\n",
    "df_replace1 = pd.read_csv(replace1_data_file)\n",
    "df_replace2 = pd.read_csv(replace2_data_file)\n",
    "\n",
    "df_ablation_min_temp = pd.read_csv(ablation_min_temp_data_file)\n",
    "df_ablation_min_temp_L2_70B = pd.read_csv(ablation_min_temp_data_file_L2_70B)\n",
    "\n",
    "df_ablation_max_temp = pd.read_csv(ablation_max_temp_data_file)\n",
    "# df_ablation_max_temp_GPT4 = pd.read_csv(ablation_max_temp_data_file_GPT4)\n",
    "\n",
    "df_ablation_length = pd.read_csv(ablation_length_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"****MAIN****\\nMain columns: {df_main.columns}\\nMain shape: {df_main.shape} \\nMain NaNs: {df_main.isna().sum()}\\n\\n\")\n",
    "print(f\"****REPLACE1****\\nReplace1 columns: {df_replace1.columns}\\nReplace1 shape: {df_replace1.shape} \\nReplace1 NaNs: {df_replace1.isna().sum()}\\n\\n\")\n",
    "print(f\"****REPLACE2****\\nReplace2 columns: {df_replace2.columns}\\nReplace2 shape: {df_replace2.shape} \\nReplace2 NaNs: {df_replace2.isna().sum()}\\n\\n\")\n",
    "\n",
    "print(f\"****ABLATION_MIN_TEMP****\\nAblation_min_temp columns: {df_ablation_min_temp.columns}\\nAblation_min_temp shape: {df_ablation_min_temp.shape} \\nAblation_min_temp NaNs: {df_ablation_min_temp.isna().sum()}\\n\\n\")\n",
    "print(f\"****ABLATION_MIN_TEMP_L2_70B****\\nAblation_min_temp_L2_70B columns: {df_ablation_min_temp_L2_70B.columns}\\nAblation_min_temp_L2_70B shape: {df_ablation_min_temp_L2_70B.shape} \\nAblation_min_temp_L2_70B NaNs: {df_ablation_min_temp_L2_70B.isna().sum()}\\n\\n\")\n",
    "\n",
    "print(f\"****ABLATION_MAX_TEMP****\\nAblation_max_temp columns: {df_ablation_max_temp.columns}\\nAblation_max_temp shape: {df_ablation_max_temp.shape} \\nAblation_max_temp NaNs: {df_ablation_max_temp.isna().sum()}\\n\\n\")\n",
    "# print(f\"****ABLATION_MAX_TEMP_GPT4****\\nAblation_max_temp_GPT4 columns: {df_ablation_max_temp_GPT4.columns}\\nAblation_max_temp_GPT4 shape: {df_ablation_max_temp_GPT4.shape} \\nAblation_max_temp_GPT4 NaNs: {df_ablation_max_temp_GPT4.isna().sum()}\\n\\n\")\n",
    "\n",
    "print(f\"****ABLATION_LENGTH****\\nAblation_length columns: {df_ablation_length.columns}\\nAblation_length shape: {df_ablation_length.shape} \\nAblation_length NaNs: {df_ablation_length.isna().sum()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the files for the main benchmark dataset\n",
    "Replace local HF models in the main dataset with the newly generated outputs that have the \"right\" max_length parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.shape, df_replace1.shape, df_replace2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_main = df_main.drop(columns=['hf_model_tiiuae/falcon-7b_jco2/falcon-7b-dolly-peft-stp-10k',\n",
    "                                 'hf_model_meta-llama/Llama-2-7b-chat-hf',\n",
    "                                 'hf_model_tiiuae/falcon-7b-instruct',\n",
    "                                 'hf_model_huggyllama/llama-7b_timdettmers/guanaco-7b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_tmp = df_merge_main.merge(df_replace1, on=['instruction','response', 'context', 'category'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_main.shape, df_merge_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_all = df_merge_tmp.merge(df_replace2, on=['instruction','response', 'context', 'category'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_all.shape, df_merge_tmp.shape, df_merge_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"****MERGE_ALL****\\nMerge_all columns: {df_merge_all.columns}\\nMerge_all shape: {df_merge_all.shape} \\nMerge_all NaNs: {df_merge_all.isna().sum()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged dataset to file\n",
    "out_filename = f\"../results/final_datasets/{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_databricks-dolly_size-2000_benchmark\"\n",
    "print(f\"Out file name: {out_filename}\")\n",
    "print(f\"Saved to: {out_filename}.csv\")\n",
    "df_merge_all.to_csv(f\"{out_filename}.csv\", index=False, escapechar='\\\\')\n",
    "print(\"Write to tsv\")\n",
    "df_merge_all.to_csv(f\"{out_filename}.tsv\", index=False, sep=\"\\t\", escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Ablation temperature max data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ablation_max_temp.shape, df_ablation_max_temp_GPT4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ablation_max_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge_ablation_max_temp = df_ablation_max_temp.drop(columns=['openai_openai/gpt-4-1106-preview'])\n",
    "# df_merge_ablation_max_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_ablation_max_temp_all = df_merge_ablation_max_temp.merge(df_ablation_max_temp_GPT4, on=['instruction','response', 'context', 'category'], how='left')\n",
    "df_merge_ablation_max_temp_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_ablation_max_temp_all.shape, df_merge_ablation_max_temp.shape, df_ablation_max_temp_GPT4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"****MERGE_ABLATION_MAX_TEMP_ALL****\\nMerge_ablation_max_temp_all columns: {df_merge_ablation_max_temp_all.columns}\\nMerge_ablation_max_temp_all shape: {df_merge_ablation_max_temp_all.shape} \\nMerge_ablation_max_temp_all NaNs: {df_merge_ablation_max_temp_all.isna().sum()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ablation_max_temp_filename = f\"../results/final_datasets/{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_databricks-dolly_size-2000_benchmark_ABLATION-TEMPERATURE-MAX\"\n",
    "print(f\"Out file name: {out_ablation_max_temp_filename}\")\n",
    "print(f\"Saved to: {out_ablation_max_temp_filename}.csv\")\n",
    "df_merge_ablation_max_temp_all.to_csv(f\"{out_ablation_max_temp_filename}.csv\", index=False, escapechar='\\\\')\n",
    "print(\"Write to tsv\")\n",
    "df_merge_ablation_max_temp_all.to_csv(f\"{out_ablation_max_temp_filename}.tsv\", index=False, sep=\"\\t\", escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation min temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ablation_min_temp.shape, df_ablation_min_temp_L2_70B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ablation_min_temp.columns, df_ablation_min_temp_L2_70B.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_ablation_min_temp = df_ablation_min_temp.drop(columns=['hf_inference_api_meta-llama/Llama-2-70b-chat-hf'])\n",
    "df_merge_ablation_min_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_ablation_min_temp_all = df_merge_ablation_min_temp.merge(df_ablation_min_temp_L2_70B, on=['instruction','response', 'context', 'category'], how='left')\n",
    "df_merge_ablation_min_temp_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_ablation_min_temp_all.shape, df_merge_ablation_min_temp.shape, df_ablation_min_temp_L2_70B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"****MERGE_ABLATION_MIN_TEMP_ALL****\\nMerge_ablation_min_temp_all columns: {df_merge_ablation_min_temp_all.columns}\\nMerge_ablation_min_temp_all shape: {df_merge_ablation_min_temp_all.shape} \\nMerge_ablation_min_temp_all NaNs: {df_merge_ablation_min_temp_all.isna().sum()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to merge ablation_min_temp\n",
    "out_ablation_min_temp_filename = f\"../results/final_datasets/{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_databricks-dolly_size-2000_benchmark_ABLATION-TEMPERATURE-MIN\"\n",
    "print(f\"Out file name: {out_ablation_min_temp_filename}\")\n",
    "print(f\"Saved to: {out_ablation_min_temp_filename}.csv\")\n",
    "df_merge_ablation_min_temp_all.to_csv(f\"{out_ablation_min_temp_filename}.csv\", index=False, escapechar='\\\\')\n",
    "print(\"Write to tsv\")\n",
    "df_merge_ablation_min_temp_all.to_csv(f\"{out_ablation_min_temp_filename}.tsv\", index=False, sep=\"\\t\", escapechar='\\\\')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to merge ablation_length\n",
    "out_ablation_length_filename = f\"../results/final_datasets/{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_databricks-dolly_size-2000_benchmark_ABLATION-LENGTH\"\n",
    "print(f\"Out file name: {out_ablation_length_filename}\")\n",
    "print(f\"Saved to: {out_ablation_length_filename}.csv\")\n",
    "df_ablation_length.to_csv(f\"{out_ablation_length_filename}.csv\", index=False, escapechar='\\\\')\n",
    "print(\"Write to tsv\")\n",
    "df_ablation_length.to_csv(f\"{out_ablation_length_filename}.tsv\", index=False, sep=\"\\t\", escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
